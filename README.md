# OpenRouterLLMComparer

üöÄ Web App de Avalia√ß√£o de LLMs
Este aplicativo permite que voc√™ envie uma pergunta para v√°rios modelos de linguagem gratuitos simultaneamente, avalie as respostas e salve os resultados para an√°lise posterior.

Estrutura do Projeto

Para organizar o seu projeto, crie os seguintes arquivos e pastas:

/llm_tester_app
|-- .streamlit/
|   |-- secrets.toml
|-- app.py
|-- requirements.txt
Passo 1: Configurar as Contas e Chaves de API

üîë OpenRouter API

Acesse o site do OpenRouter.
Crie uma conta e fa√ßa login.
V√° para a sua p√°gina de Keys (Chaves) e crie uma nova chave.
Copie a chave de API. Voc√™ a usar√° em breve.
üêò Banco de Dados Gratuito com Neon

V√° para Neon e crie uma conta gratuita.
Crie um novo projeto.
No painel do seu projeto, localize o widget Connection Details.
Copie a string de conex√£o do tipo psycopg. Ela se parecer√° com postgresql://user:password@host:port/dbname.
üîí Arquivo secrets.toml

Este arquivo armazenar√° suas chaves de forma segura. Crie o arquivo .streamlit/secrets.toml e adicione o seguinte conte√∫do, substituindo os valores pelos que voc√™ acabou de copiar:

Ini, TOML
# .streamlit/secrets.toml

OPENROUTER_API_KEY = "sk-or-v1-abc...xyz" # Sua chave da OpenRouter
DB_CONNECTION_STRING = "postgresql://user:password@host:port/dbname" # Sua string de conex√£o da Neon
Passo 2: Definir as Depend√™ncias

Crie o arquivo requirements.txt e adicione as bibliotecas Python necess√°rias para o projeto:

Plaintext
# requirements.txt

streamlit
requests
psycopg2-binary
pandas
Instale estas depend√™ncias usando o pip:
pip install -r requirements.txt

Passo 3: O C√≥digo do Aplicativo (app.py)

Este √© o c√≥digo principal do seu web app. Ele cuida da interface do usu√°rio, das chamadas de API, da intera√ß√£o com o banco de dados e da exibi√ß√£o dos resultados.

Copie e cole o c√≥digo abaixo no seu arquivo app.py:

Python
# app.py

import streamlit as st
import requests
import pandas as pd
import psycopg2
from urllib.parse import urlparse

# --- Configura√ß√£o Inicial da P√°gina e Vari√°veis ---

st.set_page_config(
    page_title="Comparador de LLMs",
    page_icon="ü§ñ",
    layout="wide",
)

# Modelos gratuitos dispon√≠veis no OpenRouter (verifique o site para a lista mais atual)
FREE_MODELS = [
    "mistralai/mistral-7b-instruct:free",
    "google/gemma-7b-it:free",
    "nousresearch/nous-hermes-2-mixtral-8x7b-dpo:free",
    "openchat/openchat-7b:free",
]

# --- Fun√ß√µes do Banco de Dados ---

# Conecta ao banco de dados usando as credenciais do Streamlit Secrets
@st.cache_resource
def get_db_connection():
    """Retorna uma conex√£o com o banco de dados PostgreSQL."""
    conn_str = st.secrets["DB_CONNECTION_STRING"]
    return psycopg2.connect(conn_str)

# Cria a tabela de resultados se ela n√£o existir
def setup_database(conn):
    """Cria a tabela de avalia√ß√µes no banco de dados, se n√£o existir."""
    with conn.cursor() as cur:
        cur.execute("""
            CREATE TABLE IF NOT EXISTS llm_evaluations (
                id SERIAL PRIMARY KEY,
                prompt TEXT NOT NULL,
                model_name VARCHAR(255) NOT NULL,
                response TEXT NOT NULL,
                rating INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        conn.commit()

# --- Fun√ß√µes da API do OpenRouter ---

@st.cache_data(show_spinner="Consultando modelos...")
def query_openrouter_model(prompt, model_name):
    """Envia uma requisi√ß√£o para a API da OpenRouter e retorna a resposta."""
    try:
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {st.secrets['OPENROUTER_API_KEY']}",
                "Content-Type": "application/json"
            },
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}]
            }
        )
        response.raise_for_status()  # Lan√ßa um erro para c√≥digos de status ruins (4xx ou 5xx)
        data = response.json()
        return data['choices'][0]['message']['content']
    except requests.exceptions.RequestException as e:
        return f"Erro na API: {e}"
    except (KeyError, IndexError) as e:
        return f"Erro ao processar a resposta da API: {e}"

# --- Interface Principal do Streamlit ---

st.title("üß™ Comparador e Avaliador de Modelos LLM")
st.markdown("Use este app para enviar uma pergunta para diferentes LLMs, avaliar as respostas e salvar os resultados.")

# Inicializa o estado da sess√£o para armazenar os resultados temporariamente
if 'responses' not in st.session_state:
    st.session_state.responses = []
if 'prompt' not in st.session_state:
    st.session_state.prompt = ""

# Conecta e configura o banco de dados
try:
    conn = get_db_connection()
    setup_database(conn)
except Exception as e:
    st.error(f"N√£o foi poss√≠vel conectar ao banco de dados: {e}")
    st.stop()

# Abas para separar as funcionalidades
tab1, tab2 = st.tabs(["Nova Avalia√ß√£o", "Rever Resultados Salvos"])

# --- Aba 1: Nova Avalia√ß√£o ---
with tab1:
    st.header("1. Fa√ßa sua Pergunta")

    selected_models = st.multiselect(
        "Selecione os modelos que deseja testar:",
        options=FREE_MODELS,
        default=FREE_MODELS
    )

    prompt_text = st.text_area("Digite sua pergunta ou comando aqui:", height=150, key="prompt_input")

    if st.button("Enviar Pergunta para os Modelos", type="primary"):
        if not prompt_text:
            st.warning("Por favor, digite uma pergunta.")
        elif not selected_models:
            st.warning("Por favor, selecione pelo menos um modelo.")
        else:
            st.session_state.prompt = prompt_text
            st.session_state.responses = []
            for model in selected_models:
                response = query_openrouter_model(prompt_text, model)
                st.session_state.responses.append({"model": model, "response": response})

    if st.session_state.responses:
        st.header("2. Avalie as Respostas")
        
        with st.form("evaluation_form"):
            ratings = {}
            for i, res in enumerate(st.session_state.responses):
                st.subheader(f"Modelo: `{res['model']}`")
                st.markdown(res['response'])
                ratings[i] = st.slider(
                    f"Nota para {res['model']}",
                    min_value=1,
                    max_value=5,
                    key=f"rating_{i}"
                )
                st.divider()

            submitted = st.form_submit_button("Salvar Avalia√ß√µes no Banco de Dados")
            if submitted:
                try:
                    with conn.cursor() as cur:
                        for i, res in enumerate(st.session_state.responses):
                            cur.execute(
                                """
                                INSERT INTO llm_evaluations (prompt, model_name, response, rating)
                                VALUES (%s, %s, %s, %s)
                                """,
                                (st.session_state.prompt, res['model'], res['response'], ratings[i])
                            )
                        conn.commit()
                    st.success("Avalia√ß√µes salvas com sucesso!")
                    # Limpa o estado para uma nova rodada
                    st.session_state.responses = []
                    st.session_state.prompt = ""
                    st.rerun()
                except Exception as e:
                    st.error(f"Erro ao salvar no banco de dados: {e}")
                    conn.rollback()


# --- Aba 2: Rever Resultados ---
with tab2:
    st.header("Resultados Salvos Anteriormente")
    
    if st.button("Atualizar Resultados"):
        st.cache_data.clear() # Limpa o cache para buscar novos dados

    try:
        df = pd.read_sql("SELECT * FROM llm_evaluations ORDER BY created_at DESC", conn)
        if not df.empty:
            st.dataframe(df, use_container_width=True)
        else:
            st.info("Nenhuma avalia√ß√£o foi salva ainda.")
    except Exception as e:
        st.error(f"Erro ao buscar os dados: {e}")

Passo 4: Executar o Aplicativo

Abra seu terminal ou prompt de comando.

Navegue at√© a pasta do seu projeto (/llm_tester_app).

Execute o seguinte comando:

Bash
streamlit run app.py
 Seu navegador abrir√° automaticamente com o aplicativo em execu√ß√£o!

Como Usar o App

Nova Avalia√ß√£o:

Na aba "Nova Avalia√ß√£o", os modelos gratuitos j√° estar√£o selecionados. Voc√™ pode alterar a sele√ß√£o se desejar.
Digite sua pergunta na caixa de texto.
Clique em "Enviar Pergunta para os Modelos". As respostas aparecer√£o abaixo.
Use os seletores deslizantes (sliders) para dar uma nota de 1 a 5 para cada resposta.
Clique em "Salvar Avalia√ß√µes no Banco de Dados" para registrar permanentemente os resultados.
Rever Resultados Salvos:

Clique na aba "Rever Resultados Salvos".
Uma tabela com todas as avalia√ß√µes anteriores ser√° exibida, mostrando o prompt, o modelo, a resposta, a nota e a data.
Clique no bot√£o "Atualizar Resultados" para buscar os dados mais recentes do banco de dados.
Com isso, voc√™ tem um web app funcional e completo para suas an√°lises de modelos de linguagem.
